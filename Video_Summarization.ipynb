{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF467AHydALd"
      },
      "source": [
        "OpenCV is an open source library which provides us with the tools to perform almost any kind of image and video processing. OpenCV is written in C++ and its primary interface is in C++.OpenCV comes with both cv and cv2 . It is a huge open-source library for computer vision, machine learning, and image processing.\n",
        "\n",
        "Processing a video means, performing operations on the video frame by frame. Frames are nothing but just the particular instance of the video in a single point of time. There may be multiple frames even in a single second. Frames can be treated as similar to an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud5fSgnfjsVi"
      },
      "source": [
        "Video streaming is not a continuous process, but a discrete one.\n",
        "That means, each time we deal with videos, we are actually dealing with the sequence of frames themselves. \n",
        "\n",
        "Each frame is just an image, which might be represented as an m x n array of pixels, where (m,n) is picture size. Each pixel might be represented as color intensity, depending on which color model we are using (gray-scale, RGB, or even multispectrum)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENnixE1cAw2p"
      },
      "source": [
        "Numpy is used to perform a wide variety of mathematical operations on arrays.A good knowledge of Numpy is required to write better optimized code with OpenCV\n",
        "\n",
        "The frames are returned as NumPy arrays by the OpenCV read function, thus using this library is essential for processing anf functionality of videos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljGvaJteChUX"
      },
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X11X1WjWCBxa"
      },
      "source": [
        "We need to create a VideoCapture object to capture a video. It accepts either the device index or the name of a video file. A number that is specified to the camera is called device index. We can select the camera by passing either 0 or 1 as an argument. After that, we can capture the video frame-by-frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXB8f_qHGE3A"
      },
      "source": [
        "video = cv2.VideoCapture('/content/1.mp4');"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCYoxnlnCVcB"
      },
      "source": [
        "To get the width, we have used the cv2.CAP_PROP_FRAME_WIDTH instance, and saved the output in the width variable.To get the height, we have used the cv2.CAP_PROP_FRAME_HEIGHT instance, and saved the output in the height variable.\n",
        "These values can be different, and it depends on the using camera or the video you have used. Threshold variable is also declared to compare the current and the previous frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ5PPtxySD7A"
      },
      "source": [
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "threshold = 20."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMYV-XDeDQRZ"
      },
      "source": [
        "To save a video in OpenCV cv.VideoWriter() method is used.\n",
        "\n",
        "Syntax: cv.VideoWriter(filename, fourcc, fps, frameSize)\n",
        "Parameters:\n",
        "filename: Input video file\n",
        "fourcc: 4-character code of codec used to compress the frames\n",
        "fps: framerate of videostream\n",
        "framesize: Height and width of frame\n",
        "\n",
        "The read() method is used to read the frames using the above-created object. \n",
        "The video is captured the frame by frame and if a frame is read, ret is True otherwise ret is false.The value of first frame is stored as previous frame. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgGtC0IkSGWX"
      },
      "source": [
        "writer = cv2.VideoWriter('final.mp4', cv2.VideoWriter_fourcc(*'MP4V'), 25, (width, height))\n",
        "ret, frame1 = video.read()\n",
        "prev_frame = frame1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ3PAQIkjWN0"
      },
      "source": [
        "Created variables unique, common , total to store specific frames. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTg_K_IgSNDc"
      },
      "source": [
        "unique = 0\n",
        "common = 0\n",
        "total = 0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci2wEQR90Aoz"
      },
      "source": [
        "An infinte loop is implied to iterate throuhg each and very frame of the video. The frames are read using .read() which returns a bool value to tell if a frame is read and the frames as a numpy array which represent thte pixels of the frames.\n",
        "\n",
        "To summarize the video we need to have frame which are unique or different from the previous frame so that we can only collect frames with something happening in them.\n",
        "\n",
        "For collecting unique frame we apply the condition were we take the difference between two consective frames and compare it with the threshold value already set in above cells.\n",
        "\n",
        "To take difference between two frames we take the difference between the each pixel of the frame then we convert negative values to positive values by using the absolute function. Then the all the values are added and divided by size of the array to get the average difference of the all pixels.\n",
        "\n",
        "If the above calculated difference is above the threshold value then the frames are considered unique otherwise they are considered common.\n",
        "\n",
        "Using the loop we calculated unique , common and total frames and later displayed their values.\n",
        "\n",
        "All the unique frames were written using .write() in the blank video -'final.mp4' already created using the VideoWriter in above cells to get the summarised video.\n",
        "\n",
        "To end the loop two conditions are used which ever becomes true first terminates the loop. One is when the read function returns the 'false' as the bool value and other is when cv2.waitKey(1) & 0xFF == ord('q') condition becomes true. waitKey() is a required building block for OpenCV video processing. waitKey is a method which displays the frame for specified milliseconds. The ‘0xFF == ord(‘q’)’ inside the ‘if’ statement is a special syntax to provide the ‘while’ loop break, by a keyboard key pressing event.\n",
        "\n",
        "After exiting the loop of frames. release() function is used to close the video file or capturing device. All the videos are closed using this function.\n",
        "\n",
        "The summarized video can be downloaded from the contents section of the google colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E62u5FlSSPJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c36fbf-6db5-4cf7-aa79-0ab8bc1a5262"
      },
      "source": [
        "while True:\n",
        "    ret, frame = video.read()   #frames are returned as numpy arrays\n",
        "    if ret is True:\n",
        "        if (((np.sum(np.absolute(frame-prev_frame))/np.size(frame)) > threshold)):\n",
        "            writer.write(frame)\n",
        "            prev_frame = frame\n",
        "            unique += 1\n",
        "        else:\n",
        "            prev_frame = frame\n",
        "            common += 1\n",
        "\n",
        "        #cv2_imshow( frame)\n",
        "        total += 1\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "           break\n",
        "     \n",
        "    else:\n",
        "       break      \n",
        "\n",
        "print(\"Total frames: \", total)\n",
        "print(\"Unique frames: \", unique)\n",
        "print(\"Common frames: \", common)\n",
        "video.release()\n",
        "writer.release()\n",
        "#cv2.destroyAllWindows()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total frames:  2607\n",
            "Unique frames:  676\n",
            "Common frames:  1931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYXG2Q37oH4C"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}